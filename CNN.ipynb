{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e359e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate multi-step 1d cnn example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import r2_score # R square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44db6d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ambient temperature (°C)</th>\n",
       "      <th>Global plane of array irradiance (W/m²)</th>\n",
       "      <th>m-Si module temperature (°C)</th>\n",
       "      <th>DC power of m-Si (W)</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.771</td>\n",
       "      <td>205.614</td>\n",
       "      <td>21.213</td>\n",
       "      <td>348</td>\n",
       "      <td>2018-05-25 07:10:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.960</td>\n",
       "      <td>266.586</td>\n",
       "      <td>20.795</td>\n",
       "      <td>412</td>\n",
       "      <td>2018-05-25 07:25:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.432</td>\n",
       "      <td>278.943</td>\n",
       "      <td>23.032</td>\n",
       "      <td>569</td>\n",
       "      <td>2018-05-25 07:45:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.397</td>\n",
       "      <td>210.042</td>\n",
       "      <td>23.655</td>\n",
       "      <td>426</td>\n",
       "      <td>2018-05-25 07:50:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.178</td>\n",
       "      <td>249.752</td>\n",
       "      <td>22.766</td>\n",
       "      <td>489</td>\n",
       "      <td>2018-05-25 08:00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ambient temperature (°C)  Global plane of array irradiance (W/m²)  \\\n",
       "0                    18.771                                  205.614   \n",
       "1                    17.960                                  266.586   \n",
       "2                    18.432                                  278.943   \n",
       "3                    18.397                                  210.042   \n",
       "4                    18.178                                  249.752   \n",
       "\n",
       "   m-Si module temperature (°C)  DC power of m-Si (W)            datetime  \n",
       "0                        21.213                   348 2018-05-25 07:10:01  \n",
       "1                        20.795                   412 2018-05-25 07:25:01  \n",
       "2                        23.032                   569 2018-05-25 07:45:01  \n",
       "3                        23.655                   426 2018-05-25 07:50:01  \n",
       "4                        22.766                   489 2018-05-25 08:00:01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excelFile = 'F:\\\\wang\\\\自学\\\\数据\\\\Preprocessed Data.xlsx'\n",
    "#读取数据，指定日期列为指标，Pandas自动将“日期”列识别为Datetime格式\n",
    "data = pd.read_excel(excelFile,sheet_name=0)\n",
    "data['Date '] = data['Date '].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "data['Time (hh:mm)'] = data['Time (hh:mm)'].apply(lambda x:x.strftime('%H:%M:%S'))\n",
    "data['datetime'] =pd.to_datetime(data['Date '] + ' ' + data['Time (hh:mm)'])\n",
    "data.drop(list(data)[0:2],axis=1,inplace=True)\n",
    "# data=data.set_index('datetime')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1481059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d975c093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "110/110 [==============================] - 2s 9ms/step - loss: 234952.2162\n",
      "Epoch 2/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 29096.9360\n",
      "Epoch 3/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 18269.6133\n",
      "Epoch 4/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 28175.9266\n",
      "Epoch 5/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 14286.5954\n",
      "Epoch 6/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 16368.0120\n",
      "Epoch 7/350\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 11287.5465\n",
      "Epoch 8/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 13242.6416\n",
      "Epoch 9/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 12569.7212\n",
      "Epoch 10/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 13789.7823\n",
      "Epoch 11/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 11165.0398\n",
      "Epoch 12/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 13339.7705\n",
      "Epoch 13/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 15550.1057\n",
      "Epoch 14/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 11665.4270\n",
      "Epoch 15/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 10963.8267\n",
      "Epoch 16/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 9412.4790\n",
      "Epoch 17/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8814.1356\n",
      "Epoch 18/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 9868.2990\n",
      "Epoch 19/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 10337.6062\n",
      "Epoch 20/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 11752.4886\n",
      "Epoch 21/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 9179.3648\n",
      "Epoch 22/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 9239.6202\n",
      "Epoch 23/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 13642.9700\n",
      "Epoch 24/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8588.3603\n",
      "Epoch 25/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8207.5956\n",
      "Epoch 26/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8474.5493\n",
      "Epoch 27/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8067.0844\n",
      "Epoch 28/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8672.2922\n",
      "Epoch 29/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8540.9232\n",
      "Epoch 30/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8098.0321\n",
      "Epoch 31/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 7544.7966\n",
      "Epoch 32/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8004.3157\n",
      "Epoch 33/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 7519.8802\n",
      "Epoch 34/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 7463.1554\n",
      "Epoch 35/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 7744.1206\n",
      "Epoch 36/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 6330.7130\n",
      "Epoch 37/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 6165.0131\n",
      "Epoch 38/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 6575.7971\n",
      "Epoch 39/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 7084.8834\n",
      "Epoch 40/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 6149.6100\n",
      "Epoch 41/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 9007.3626\n",
      "Epoch 42/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 7877.6069\n",
      "Epoch 43/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5291.9929\n",
      "Epoch 44/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 11429.7452\n",
      "Epoch 45/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8297.4915\n",
      "Epoch 46/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 8956.5107\n",
      "Epoch 47/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 6536.3114\n",
      "Epoch 48/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 6360.3201\n",
      "Epoch 49/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5588.3825\n",
      "Epoch 50/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5340.7762\n",
      "Epoch 51/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5616.7009\n",
      "Epoch 52/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5916.6223\n",
      "Epoch 53/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4575.6324\n",
      "Epoch 54/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4675.2630\n",
      "Epoch 55/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5048.1422\n",
      "Epoch 56/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5762.2502\n",
      "Epoch 57/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 7656.3682\n",
      "Epoch 58/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5503.7862\n",
      "Epoch 59/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5690.8503\n",
      "Epoch 60/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4421.1749\n",
      "Epoch 61/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 9036.2272\n",
      "Epoch 62/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4785.3063\n",
      "Epoch 63/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4178.9394\n",
      "Epoch 64/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4441.0131\n",
      "Epoch 65/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4341.3320\n",
      "Epoch 66/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5363.2438\n",
      "Epoch 67/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3745.2420\n",
      "Epoch 68/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4023.1671\n",
      "Epoch 69/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3842.5150\n",
      "Epoch 70/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3803.9026\n",
      "Epoch 71/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5531.7839\n",
      "Epoch 72/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3769.1434\n",
      "Epoch 73/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4507.4243\n",
      "Epoch 74/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3535.1220\n",
      "Epoch 75/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3325.8776\n",
      "Epoch 76/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3423.8050\n",
      "Epoch 77/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3665.0561\n",
      "Epoch 78/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3354.2361\n",
      "Epoch 79/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3359.5793\n",
      "Epoch 80/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4134.1173\n",
      "Epoch 81/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3196.2125\n",
      "Epoch 82/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3601.3334\n",
      "Epoch 83/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 5081.4395\n",
      "Epoch 84/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3872.1710\n",
      "Epoch 85/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2877.5482\n",
      "Epoch 86/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2714.8252\n",
      "Epoch 87/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2919.8661\n",
      "Epoch 88/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2787.3916\n",
      "Epoch 89/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2444.2798\n",
      "Epoch 90/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 4381.6436\n",
      "Epoch 91/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3767.1570\n",
      "Epoch 92/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 2970.7765\n",
      "Epoch 93/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 2462.5525\n",
      "Epoch 94/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2605.2446\n",
      "Epoch 95/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3707.8615\n",
      "Epoch 96/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 1s 9ms/step - loss: 3512.5429\n",
      "Epoch 97/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2228.5121\n",
      "Epoch 98/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2437.7287\n",
      "Epoch 99/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1977.2590\n",
      "Epoch 100/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2871.4750\n",
      "Epoch 101/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2321.7845\n",
      "Epoch 102/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2313.5239\n",
      "Epoch 103/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2297.1272\n",
      "Epoch 104/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2357.1869\n",
      "Epoch 105/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2124.8154\n",
      "Epoch 106/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2734.2606\n",
      "Epoch 107/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2006.9576\n",
      "Epoch 108/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1983.5069\n",
      "Epoch 109/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1806.4528\n",
      "Epoch 110/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2046.2575\n",
      "Epoch 111/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1979.1759\n",
      "Epoch 112/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1773.4629\n",
      "Epoch 113/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1728.5362\n",
      "Epoch 114/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1624.5108\n",
      "Epoch 115/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1864.5474\n",
      "Epoch 116/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1745.3612\n",
      "Epoch 117/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2755.2254\n",
      "Epoch 118/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1758.3302\n",
      "Epoch 119/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1407.7043\n",
      "Epoch 120/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1753.8472\n",
      "Epoch 121/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2116.8288\n",
      "Epoch 122/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2042.8002\n",
      "Epoch 123/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 6662.2744\n",
      "Epoch 124/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2337.4952\n",
      "Epoch 125/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1844.9172\n",
      "Epoch 126/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1417.2144\n",
      "Epoch 127/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1517.9253\n",
      "Epoch 128/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1157.4397\n",
      "Epoch 129/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1133.2045\n",
      "Epoch 130/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1118.5614\n",
      "Epoch 131/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1257.7176\n",
      "Epoch 132/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1344.1843\n",
      "Epoch 133/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1254.9485\n",
      "Epoch 134/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1341.4152\n",
      "Epoch 135/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1574.9728\n",
      "Epoch 136/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2540.2434\n",
      "Epoch 137/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1366.1360\n",
      "Epoch 138/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1215.5735\n",
      "Epoch 139/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1548.1088\n",
      "Epoch 140/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1397.8785\n",
      "Epoch 141/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1297.0666\n",
      "Epoch 142/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1182.6825\n",
      "Epoch 143/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2112.7708\n",
      "Epoch 144/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1846.6097\n",
      "Epoch 145/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 1473.0786\n",
      "Epoch 146/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1471.0297\n",
      "Epoch 147/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1143.6751\n",
      "Epoch 148/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1035.1666\n",
      "Epoch 149/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 976.0817\n",
      "Epoch 150/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 959.5587\n",
      "Epoch 151/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 985.1140\n",
      "Epoch 152/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 988.0553\n",
      "Epoch 153/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1134.9751\n",
      "Epoch 154/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1583.6353\n",
      "Epoch 155/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1186.1702\n",
      "Epoch 156/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1438.3406\n",
      "Epoch 157/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1164.7704\n",
      "Epoch 158/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 912.7741\n",
      "Epoch 159/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1283.2042\n",
      "Epoch 160/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 919.3857\n",
      "Epoch 161/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1053.1307\n",
      "Epoch 162/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 1168.6952\n",
      "Epoch 163/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 877.0232\n",
      "Epoch 164/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1038.3584\n",
      "Epoch 165/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1068.7231\n",
      "Epoch 166/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 896.0341\n",
      "Epoch 167/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1190.9212\n",
      "Epoch 168/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1761.4830\n",
      "Epoch 169/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 961.8410\n",
      "Epoch 170/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 835.7947\n",
      "Epoch 171/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 857.8983\n",
      "Epoch 172/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 760.4665\n",
      "Epoch 173/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 734.7008\n",
      "Epoch 174/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 736.6540\n",
      "Epoch 175/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 993.1003\n",
      "Epoch 176/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2030.0222\n",
      "Epoch 177/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1368.4698\n",
      "Epoch 178/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1166.6625\n",
      "Epoch 179/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 767.7576\n",
      "Epoch 180/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 899.0552\n",
      "Epoch 181/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 669.0200\n",
      "Epoch 182/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 790.3655\n",
      "Epoch 183/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1573.5746\n",
      "Epoch 184/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 822.6881\n",
      "Epoch 185/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 680.9087\n",
      "Epoch 186/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 667.2756\n",
      "Epoch 187/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 686.5338\n",
      "Epoch 188/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 703.8971\n",
      "Epoch 189/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 793.0595\n",
      "Epoch 190/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 1s 10ms/step - loss: 1044.0622\n",
      "Epoch 191/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 636.7284: 0s \n",
      "Epoch 192/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1391.3217\n",
      "Epoch 193/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1204.0446\n",
      "Epoch 194/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 959.0292\n",
      "Epoch 195/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1429.5104\n",
      "Epoch 196/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 767.0174\n",
      "Epoch 197/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 722.6716\n",
      "Epoch 198/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 736.2152\n",
      "Epoch 199/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 615.6632\n",
      "Epoch 200/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 843.8422\n",
      "Epoch 201/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 573.8959\n",
      "Epoch 202/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 589.6881\n",
      "Epoch 203/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 595.5447\n",
      "Epoch 204/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1088.4429\n",
      "Epoch 205/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2056.0673\n",
      "Epoch 206/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 947.5020\n",
      "Epoch 207/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 729.4428\n",
      "Epoch 208/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 614.4911\n",
      "Epoch 209/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 694.8114\n",
      "Epoch 210/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 585.3967\n",
      "Epoch 211/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2157.9349\n",
      "Epoch 212/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 2543.0147\n",
      "Epoch 213/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1107.4620\n",
      "Epoch 214/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 865.0627\n",
      "Epoch 215/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 597.7561\n",
      "Epoch 216/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 1397.6200\n",
      "Epoch 217/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 774.8382\n",
      "Epoch 218/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 514.6803\n",
      "Epoch 219/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 812.1497\n",
      "Epoch 220/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 514.4803\n",
      "Epoch 221/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 534.6551\n",
      "Epoch 222/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 728.7868\n",
      "Epoch 223/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 528.9637\n",
      "Epoch 224/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 540.7281\n",
      "Epoch 225/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 464.8364\n",
      "Epoch 226/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 700.1127\n",
      "Epoch 227/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 576.0082\n",
      "Epoch 228/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 530.8602\n",
      "Epoch 229/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1295.9679\n",
      "Epoch 230/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 703.3035\n",
      "Epoch 231/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 746.8168\n",
      "Epoch 232/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 831.8396\n",
      "Epoch 233/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 532.9818\n",
      "Epoch 234/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 532.8042\n",
      "Epoch 235/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 620.9893\n",
      "Epoch 236/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 552.5339\n",
      "Epoch 237/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 538.3576\n",
      "Epoch 238/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1033.8335\n",
      "Epoch 239/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 635.5437\n",
      "Epoch 240/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 864.8132\n",
      "Epoch 241/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 610.8851\n",
      "Epoch 242/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 637.7564\n",
      "Epoch 243/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 536.7132\n",
      "Epoch 244/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 486.0270\n",
      "Epoch 245/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 517.5097\n",
      "Epoch 246/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 624.2143\n",
      "Epoch 247/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 864.4621\n",
      "Epoch 248/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 464.9028\n",
      "Epoch 249/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 653.1626\n",
      "Epoch 250/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 968.1115\n",
      "Epoch 251/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 813.4639\n",
      "Epoch 252/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 586.3609\n",
      "Epoch 253/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 574.8295\n",
      "Epoch 254/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 593.0845\n",
      "Epoch 255/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1052.6509\n",
      "Epoch 256/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 565.8804\n",
      "Epoch 257/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 510.6590\n",
      "Epoch 258/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 396.4763\n",
      "Epoch 259/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 553.4909\n",
      "Epoch 260/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 759.1064\n",
      "Epoch 261/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 683.1676\n",
      "Epoch 262/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 698.0572\n",
      "Epoch 263/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 731.4891\n",
      "Epoch 264/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 458.6215\n",
      "Epoch 265/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 575.3600\n",
      "Epoch 266/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 385.0589\n",
      "Epoch 267/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 387.0521\n",
      "Epoch 268/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 462.7047\n",
      "Epoch 269/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 532.5605\n",
      "Epoch 270/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 532.1419\n",
      "Epoch 271/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 820.3157\n",
      "Epoch 272/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 575.7323\n",
      "Epoch 273/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 560.0673\n",
      "Epoch 274/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1741.4864\n",
      "Epoch 275/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1081.7230\n",
      "Epoch 276/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 737.6949\n",
      "Epoch 277/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 412.1188\n",
      "Epoch 278/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 305.1951\n",
      "Epoch 279/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 423.0567\n",
      "Epoch 280/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 450.6953\n",
      "Epoch 281/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 319.8339\n",
      "Epoch 282/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 407.3410\n",
      "Epoch 283/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 540.4760\n",
      "Epoch 284/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 520.3355\n",
      "Epoch 285/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 1s 9ms/step - loss: 2475.0323\n",
      "Epoch 286/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 959.0243\n",
      "Epoch 287/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 502.3832\n",
      "Epoch 288/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 343.0283\n",
      "Epoch 289/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 359.8790\n",
      "Epoch 290/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 346.3153\n",
      "Epoch 291/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 435.4944\n",
      "Epoch 292/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 359.9592\n",
      "Epoch 293/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 336.6144\n",
      "Epoch 294/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 339.8583\n",
      "Epoch 295/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 327.8738\n",
      "Epoch 296/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 447.7850\n",
      "Epoch 297/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 439.2776\n",
      "Epoch 298/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 470.7590\n",
      "Epoch 299/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1426.9471\n",
      "Epoch 300/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 715.3212\n",
      "Epoch 301/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 465.1011\n",
      "Epoch 302/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 1332.1300\n",
      "Epoch 303/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 630.7332\n",
      "Epoch 304/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 427.2518\n",
      "Epoch 305/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 766.6017\n",
      "Epoch 306/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 392.6955\n",
      "Epoch 307/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 519.4931\n",
      "Epoch 308/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 377.2189\n",
      "Epoch 309/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 352.1249\n",
      "Epoch 310/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 301.0790\n",
      "Epoch 311/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 396.6650\n",
      "Epoch 312/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 525.5574\n",
      "Epoch 313/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 723.1172\n",
      "Epoch 314/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 411.0278\n",
      "Epoch 315/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 807.9303\n",
      "Epoch 316/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 425.5681\n",
      "Epoch 317/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 301.9461\n",
      "Epoch 318/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 307.1835\n",
      "Epoch 319/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 442.4832\n",
      "Epoch 320/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 468.5905\n",
      "Epoch 321/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 659.6256\n",
      "Epoch 322/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 575.8146\n",
      "Epoch 323/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 614.1022\n",
      "Epoch 324/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 445.9404: 0s - loss\n",
      "Epoch 325/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 875.4736\n",
      "Epoch 326/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 747.8279\n",
      "Epoch 327/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 387.8324\n",
      "Epoch 328/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 350.7302\n",
      "Epoch 329/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 294.9350\n",
      "Epoch 330/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 316.3843\n",
      "Epoch 331/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 285.3325\n",
      "Epoch 332/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 259.7258\n",
      "Epoch 333/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 279.5078\n",
      "Epoch 334/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 557.1514\n",
      "Epoch 335/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 381.9146\n",
      "Epoch 336/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 502.7308\n",
      "Epoch 337/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 630.0088\n",
      "Epoch 338/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 435.2671\n",
      "Epoch 339/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 583.3278\n",
      "Epoch 340/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 815.5271\n",
      "Epoch 341/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 463.2024\n",
      "Epoch 342/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 929.0540\n",
      "Epoch 343/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 715.6978\n",
      "Epoch 344/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 386.1051\n",
      "Epoch 345/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 341.4180\n",
      "Epoch 346/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 312.7979\n",
      "Epoch 347/350\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 285.6295\n",
      "Epoch 348/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 410.4509\n",
      "Epoch 349/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 375.2793\n",
      "Epoch 350/350\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 718.9827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb4c5e6370>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = data['Ambient temperature (°C)'].values\n",
    "in_seq2 = data['Global plane of array irradiance (W/m²)'].values\n",
    "in_seq3 = data['m-Si module temperature (°C)'].values\n",
    "in_seq4 = data['DC power of m-Si (W)'].values\n",
    "out_seq = data['DC power of m-Si (W)'].values\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "in_seq4 = in_seq4.reshape((len(in_seq4), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2,in_seq3,in_seq4, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out =117 , 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "# flatten input\n",
    "n_input = X.shape[1] * X.shape[2]\n",
    "n_features = X.shape[2]\n",
    "# X = X.reshape((X.shape[0], n_input))\n",
    "X_train = X[:int(len(X)*0.7)]\n",
    "y_train = y[:int(len(X)*0.7)]\n",
    "X_test = X[int(len(X)*0.7):]\n",
    "y_test = y[int(len(X)*0.7):]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X_train, y_train, epochs=350, verbose=1)\n",
    "# demonstrate prediction\n",
    "# x_input = array([[70, 75], [80, 85], [90, 95]])\n",
    "# x_input = x_input.reshape((1, n_input))\n",
    "# yhat = model.predict(x_input, verbose=0)\n",
    "# print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "551185c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1767.1678 , 1745.8036 , 1730.5574 ],\n",
       "       [1765.2599 , 1746.399  , 1715.393  ],\n",
       "       [1746.6337 , 1719.7883 , 1694.5754 ],\n",
       "       ...,\n",
       "       [ 410.09604,  366.40857,  314.95407],\n",
       "       [ 342.98956,  341.64468,  266.37192],\n",
       "       [ 321.1411 ,  262.72015,  242.52455]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(X_test, verbose=0)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4c252c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1736., 1708., 1702.],\n",
       "       [1708., 1702., 1688.],\n",
       "       [1702., 1688., 1672.],\n",
       "       ...,\n",
       "       [ 384.,  341.,  310.],\n",
       "       [ 341.,  310.,  274.],\n",
       "       [ 310.,  274.,  241.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfdb3a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = pd.DataFrame(y_test)\n",
    "y_p = pd.DataFrame(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb754f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true,y_pred):\n",
    "    SSE = sum((y_true-y_pred)**2)\n",
    "    MSE = SSE/len(y_true)\n",
    "    RMSE = MSE**(1/2)\n",
    "    MAE = sum(abs(y_true-y_pred))/len(y_true)\n",
    "    MAPE = sum(abs(y_true-y_pred)/y_true)/len(y_true)*100\n",
    "    SD = (sum((abs(y_true-y_pred)-sum(abs(y_true-y_pred))/len(y_true))**2)/len(y_true))**(1/2)\n",
    "    r2s = r2_score(y_true, y_pred)\n",
    "    print('MSE: ', MSE, '\\n', 'RMSE: ', RMSE, '\\n','MAE: ', MAE, '\\n','MAPE: ', MAPE, '\\n','SD: ', SD, '\\n', 'R square: ', r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b2b3f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1367.0298705566486 \n",
      " RMSE:  36.973367043814775 \n",
      " MAE:  33.74812028242305 \n",
      " MAPE:  2.803283843065757 \n",
      " SD:  15.102789409898907 \n",
      " R square:  0.9936161056677697\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_t[0],y_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19245aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308533cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a97813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cbff92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllearning",
   "language": "python",
   "name": "mllearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
