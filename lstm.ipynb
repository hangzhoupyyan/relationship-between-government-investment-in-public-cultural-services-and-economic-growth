{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e359e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate lstm example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import r2_score # R square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44db6d62",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Preprocessed Data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/44/20v1h1817mbb5rvtwjk_v93m0000gn/T/ipykernel_17528/2270762831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexcelFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Preprocessed Data.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#读取数据，指定日期列为指标，Pandas自动将“日期”列识别为Datetime格式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcelFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date '\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time (hh:mm)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time (hh:mm)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     ) as handle:\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Preprocessed Data.xlsx'"
     ]
    }
   ],
   "source": [
    "excelFile = 'Preprocessed Data.xlsx'\n",
    "#读取数据，指定日期列为指标，Pandas自动将“日期”列识别为Datetime格式\n",
    "data = pd.read_excel(excelFile,sheet_name=0)\n",
    "data['Date '] = data['Date '].apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "data['Time (hh:mm)'] = data['Time (hh:mm)'].apply(lambda x:x.strftime('%H:%M:%S'))\n",
    "data['datetime'] =pd.to_datetime(data['Date '] + ' ' + data['Time (hh:mm)'])\n",
    "data.drop(list(data)[0:2],axis=1,inplace=True)\n",
    "# data=data.set_index('datetime')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1481059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d975c093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "112/112 [==============================] - 4s 11ms/step - loss: 1303667.4320\n",
      "Epoch 2/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 289405.7027\n",
      "Epoch 3/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 188314.5961\n",
      "Epoch 4/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 161499.4405\n",
      "Epoch 5/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 122669.8055\n",
      "Epoch 6/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 106530.7796\n",
      "Epoch 7/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 64113.4514\n",
      "Epoch 8/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 119705.1148\n",
      "Epoch 9/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 58168.4621\n",
      "Epoch 10/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 49298.0272\n",
      "Epoch 11/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 47652.4073\n",
      "Epoch 12/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 33492.0744\n",
      "Epoch 13/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 34184.9545\n",
      "Epoch 14/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 31516.4386\n",
      "Epoch 15/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 29196.9406\n",
      "Epoch 16/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 34037.1372\n",
      "Epoch 17/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 31296.3984\n",
      "Epoch 18/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 28464.9810\n",
      "Epoch 19/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 27200.7673\n",
      "Epoch 20/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 27061.6149\n",
      "Epoch 21/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 21924.3506\n",
      "Epoch 22/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 23679.6917\n",
      "Epoch 23/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 22741.8820\n",
      "Epoch 24/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 22019.6347\n",
      "Epoch 25/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 21119.4132\n",
      "Epoch 26/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 23171.0444\n",
      "Epoch 27/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 20643.8346\n",
      "Epoch 28/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 18204.4134\n",
      "Epoch 29/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 20271.7529\n",
      "Epoch 30/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 18837.8632\n",
      "Epoch 31/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 18607.6550\n",
      "Epoch 32/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 18397.1237\n",
      "Epoch 33/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 18074.2740\n",
      "Epoch 34/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 17936.0709\n",
      "Epoch 35/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 21519.7089\n",
      "Epoch 36/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 20431.0859\n",
      "Epoch 37/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 19582.9665\n",
      "Epoch 38/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 18857.4673\n",
      "Epoch 39/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 18075.5474\n",
      "Epoch 40/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 18164.8856\n",
      "Epoch 41/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 19549.1424\n",
      "Epoch 42/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 16186.7112\n",
      "Epoch 43/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 16745.7086\n",
      "Epoch 44/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 15566.0730\n",
      "Epoch 45/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 15542.8549\n",
      "Epoch 46/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 15762.0144\n",
      "Epoch 47/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 16122.5505\n",
      "Epoch 48/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14366.7061\n",
      "Epoch 49/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 17215.9382\n",
      "Epoch 50/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 16929.6746\n",
      "Epoch 51/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 16654.4811\n",
      "Epoch 52/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14774.7825\n",
      "Epoch 53/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 14664.8192\n",
      "Epoch 54/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 17597.7524\n",
      "Epoch 55/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13162.8211\n",
      "Epoch 56/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13328.2724\n",
      "Epoch 57/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 16464.1215A: 0s - \n",
      "Epoch 58/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14599.1482\n",
      "Epoch 59/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14847.9209\n",
      "Epoch 60/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 15280.9105\n",
      "Epoch 61/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13071.9034\n",
      "Epoch 62/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 13069.5365\n",
      "Epoch 63/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12332.9254\n",
      "Epoch 64/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13699.4752\n",
      "Epoch 65/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13930.2083\n",
      "Epoch 66/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13852.1933\n",
      "Epoch 67/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13759.5675\n",
      "Epoch 68/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13572.3902\n",
      "Epoch 69/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 14042.2353\n",
      "Epoch 70/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12670.5045\n",
      "Epoch 71/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 13329.2908\n",
      "Epoch 72/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11749.0255\n",
      "Epoch 73/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12339.1285\n",
      "Epoch 74/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12602.1107\n",
      "Epoch 75/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13614.2114\n",
      "Epoch 76/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 13120.7532\n",
      "Epoch 77/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 12973.6759\n",
      "Epoch 78/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13543.0187\n",
      "Epoch 79/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 13070.8292\n",
      "Epoch 80/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 12006.9893\n",
      "Epoch 81/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13492.5511\n",
      "Epoch 82/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 13650.5880\n",
      "Epoch 83/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11556.0780\n",
      "Epoch 84/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12207.8118\n",
      "Epoch 85/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12163.7826\n",
      "Epoch 86/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12374.6231\n",
      "Epoch 87/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12638.3402\n",
      "Epoch 88/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 12332.0600\n",
      "Epoch 89/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11288.7648\n",
      "Epoch 90/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12186.8098\n",
      "Epoch 91/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12912.2261\n",
      "Epoch 92/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12350.9584\n",
      "Epoch 93/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13613.8594\n",
      "Epoch 94/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12478.3739\n",
      "Epoch 95/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11558.7511\n",
      "Epoch 96/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11828.6336\n",
      "Epoch 97/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10877.3682\n",
      "Epoch 98/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12692.5279\n",
      "Epoch 99/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13288.4274\n",
      "Epoch 100/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11739.7284\n",
      "Epoch 101/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12187.3168\n",
      "Epoch 102/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12256.6090\n",
      "Epoch 103/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12534.0738\n",
      "Epoch 104/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12059.2814\n",
      "Epoch 105/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12172.2715\n",
      "Epoch 106/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14401.1027\n",
      "Epoch 107/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 12267.4381\n",
      "Epoch 108/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 10994.5335\n",
      "Epoch 109/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12391.5696\n",
      "Epoch 110/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12502.2603\n",
      "Epoch 111/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11980.1550\n",
      "Epoch 112/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 13612.3668\n",
      "Epoch 113/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13896.7548\n",
      "Epoch 114/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12312.8981\n",
      "Epoch 115/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12210.9489\n",
      "Epoch 116/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13248.4885\n",
      "Epoch 117/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 63102.3609\n",
      "Epoch 118/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 47392.0126\n",
      "Epoch 119/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 18294.0698\n",
      "Epoch 120/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 18183.2788\n",
      "Epoch 121/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 16530.4214\n",
      "Epoch 122/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14440.7471\n",
      "Epoch 123/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 15523.0733\n",
      "Epoch 124/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14996.0154\n",
      "Epoch 125/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12560.3196\n",
      "Epoch 126/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14088.3330\n",
      "Epoch 127/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12596.5381\n",
      "Epoch 128/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12764.9388\n",
      "Epoch 129/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14873.2129\n",
      "Epoch 130/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 12515.6515\n",
      "Epoch 131/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14749.5008\n",
      "Epoch 132/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13022.1155\n",
      "Epoch 133/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14562.8404\n",
      "Epoch 134/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13453.3446\n",
      "Epoch 135/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11703.9203\n",
      "Epoch 136/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12906.7502\n",
      "Epoch 137/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 12727.9961\n",
      "Epoch 138/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10553.6277\n",
      "Epoch 139/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12993.0899\n",
      "Epoch 140/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12636.5920\n",
      "Epoch 141/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11197.8266\n",
      "Epoch 142/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 11189.0603\n",
      "Epoch 143/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11802.6408\n",
      "Epoch 144/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11711.5489\n",
      "Epoch 145/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13130.8835\n",
      "Epoch 146/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10534.8454\n",
      "Epoch 147/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 11873.7884\n",
      "Epoch 148/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10950.9453\n",
      "Epoch 149/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11056.7842\n",
      "Epoch 150/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11735.5340\n",
      "Epoch 151/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10633.0327\n",
      "Epoch 152/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10675.1324\n",
      "Epoch 153/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10904.6883\n",
      "Epoch 154/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11250.2420\n",
      "Epoch 155/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11341.3407\n",
      "Epoch 156/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12382.0490\n",
      "Epoch 157/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13094.6926\n",
      "Epoch 158/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 12319.1513\n",
      "Epoch 159/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10683.7062\n",
      "Epoch 160/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12389.8699\n",
      "Epoch 161/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11405.9136\n",
      "Epoch 162/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11615.1379\n",
      "Epoch 163/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10504.3730\n",
      "Epoch 164/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 9428.2588\n",
      "Epoch 165/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12330.4285\n",
      "Epoch 166/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11151.4853\n",
      "Epoch 167/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11179.4245\n",
      "Epoch 168/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 10624.3373: 0s - loss: 10504.9\n",
      "Epoch 169/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 9529.9983\n",
      "Epoch 170/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10553.9470\n",
      "Epoch 171/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12171.7203\n",
      "Epoch 172/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13764.4210\n",
      "Epoch 173/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11905.7002\n",
      "Epoch 174/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10950.3924\n",
      "Epoch 175/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11047.2130\n",
      "Epoch 176/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12245.5752\n",
      "Epoch 177/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10918.5092\n",
      "Epoch 178/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12580.0274\n",
      "Epoch 179/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12685.2490\n",
      "Epoch 180/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10184.9963\n",
      "Epoch 181/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11522.4319\n",
      "Epoch 182/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10696.2262A: 0s - loss: 1\n",
      "Epoch 183/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10957.1628\n",
      "Epoch 184/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10848.4004\n",
      "Epoch 185/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12047.9419\n",
      "Epoch 186/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 9ms/step - loss: 10355.3052\n",
      "Epoch 187/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 9205.3087\n",
      "Epoch 188/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10205.6453\n",
      "Epoch 189/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11112.2601\n",
      "Epoch 190/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11030.0529\n",
      "Epoch 191/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10766.6608\n",
      "Epoch 192/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 11249.2457\n",
      "Epoch 193/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10961.7038\n",
      "Epoch 194/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11508.5142\n",
      "Epoch 195/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11245.3312\n",
      "Epoch 196/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12299.0239\n",
      "Epoch 197/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10950.3028\n",
      "Epoch 198/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10181.1725\n",
      "Epoch 199/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13798.1997\n",
      "Epoch 200/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10799.1485\n",
      "Epoch 201/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10137.9265\n",
      "Epoch 202/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11580.6563\n",
      "Epoch 203/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10637.7174\n",
      "Epoch 204/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 11329.8432\n",
      "Epoch 205/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10435.6620\n",
      "Epoch 206/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10534.0504\n",
      "Epoch 207/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10958.2402\n",
      "Epoch 208/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 11192.9826\n",
      "Epoch 209/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10290.5789\n",
      "Epoch 210/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10827.9408\n",
      "Epoch 211/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 11357.8280\n",
      "Epoch 212/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10905.9395\n",
      "Epoch 213/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10605.5401\n",
      "Epoch 214/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11474.0049\n",
      "Epoch 215/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11041.7627\n",
      "Epoch 216/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11085.1056\n",
      "Epoch 217/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12357.3852\n",
      "Epoch 218/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 11350.4464\n",
      "Epoch 219/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 16402.9864\n",
      "Epoch 220/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 15894.3807\n",
      "Epoch 221/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13464.0510\n",
      "Epoch 222/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12467.5960\n",
      "Epoch 223/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12482.3534\n",
      "Epoch 224/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12228.2246\n",
      "Epoch 225/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 15600.3922\n",
      "Epoch 226/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11470.4305\n",
      "Epoch 227/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12700.0512\n",
      "Epoch 228/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13632.9736\n",
      "Epoch 229/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11018.7263\n",
      "Epoch 230/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10990.5765\n",
      "Epoch 231/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 13672.0829\n",
      "Epoch 232/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10810.7604\n",
      "Epoch 233/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11886.8697\n",
      "Epoch 234/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12314.4111\n",
      "Epoch 235/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14546.1331\n",
      "Epoch 236/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12433.6599\n",
      "Epoch 237/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12470.6300A: 0s - loss\n",
      "Epoch 238/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13233.8384\n",
      "Epoch 239/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11831.8145\n",
      "Epoch 240/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12112.8134\n",
      "Epoch 241/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 14071.4216\n",
      "Epoch 242/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10902.5378\n",
      "Epoch 243/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 11285.2472\n",
      "Epoch 244/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11271.2403\n",
      "Epoch 245/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11736.3605A: 0s -\n",
      "Epoch 246/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11915.9008\n",
      "Epoch 247/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12032.3629\n",
      "Epoch 248/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12220.3592\n",
      "Epoch 249/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10892.0557\n",
      "Epoch 250/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11627.0071\n",
      "Epoch 251/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11296.0948\n",
      "Epoch 252/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11677.7577\n",
      "Epoch 253/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10551.4903\n",
      "Epoch 254/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10640.7795\n",
      "Epoch 255/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12767.4748\n",
      "Epoch 256/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12556.2574\n",
      "Epoch 257/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10661.4962\n",
      "Epoch 258/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11199.6766\n",
      "Epoch 259/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10429.2490\n",
      "Epoch 260/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11389.8547\n",
      "Epoch 261/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 11972.6006\n",
      "Epoch 262/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11003.1283\n",
      "Epoch 263/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 10614.5642\n",
      "Epoch 264/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10753.2475\n",
      "Epoch 265/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11088.7172\n",
      "Epoch 266/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11448.6590\n",
      "Epoch 267/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10999.5850\n",
      "Epoch 268/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10570.7355\n",
      "Epoch 269/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 9887.0789\n",
      "Epoch 270/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10984.8040\n",
      "Epoch 271/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10534.8945\n",
      "Epoch 272/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10869.6773\n",
      "Epoch 273/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10972.1449\n",
      "Epoch 274/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11574.1015\n",
      "Epoch 275/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11129.3518\n",
      "Epoch 276/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 12307.7462\n",
      "Epoch 277/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 10251.3009\n",
      "Epoch 278/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13178.4609\n",
      "Epoch 279/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 9ms/step - loss: 9448.7632\n",
      "Epoch 280/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11579.2976\n",
      "Epoch 281/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11386.5524\n",
      "Epoch 282/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 9674.8923\n",
      "Epoch 283/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 13118.6651\n",
      "Epoch 284/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10952.7845\n",
      "Epoch 285/300\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 10841.4298\n",
      "Epoch 286/300\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 12691.1222\n",
      "Epoch 287/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 11735.4536\n",
      "Epoch 288/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11431.9848\n",
      "Epoch 289/300\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 9834.4338\n",
      "Epoch 290/300\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 11164.7144\n",
      "Epoch 291/300\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 10473.4831\n",
      "Epoch 292/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10181.1198\n",
      "Epoch 293/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 11888.5677\n",
      "Epoch 294/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 11285.0349\n",
      "Epoch 295/300\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 10478.9848\n",
      "Epoch 296/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10877.3421\n",
      "Epoch 297/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 11514.7262\n",
      "Epoch 298/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10763.9979\n",
      "Epoch 299/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10916.4461\n",
      "Epoch 300/300\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 10543.1817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb247f0f70>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = data['Ambient temperature (°C)'].values\n",
    "in_seq2 = data['Global plane of array irradiance (W/m²)'].values\n",
    "in_seq3 = data['m-Si module temperature (°C)'].values\n",
    "in_seq4 = data['DC power of m-Si (W)'].values\n",
    "out_seq = data['DC power of m-Si (W)'].values\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "in_seq4 = in_seq4.reshape((len(in_seq4), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2,in_seq3,in_seq4, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out =117 , 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "# flatten input\n",
    "n_input = X.shape[1] * X.shape[2]\n",
    "n_features = X.shape[2]\n",
    "# X = X.reshape((X.shape[0], n_input))\n",
    "X_train = X[:int(len(X)*0.7)]\n",
    "y_train = y[:int(len(X)*0.7)]\n",
    "X_test = X[int(len(X)*0.7):]\n",
    "y_test = y[int(len(X)*0.7):]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu',  input_shape=(n_steps_in, n_features)))\n",
    "# model.add(LSTM(4, activation='relu'))\n",
    "# model.add(Dense(100))\n",
    "# model.add(Dense(50))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X_train, y_train, epochs=300,verbose=1)\n",
    "# demonstrate prediction\n",
    "# x_input = array([[70, 75], [80, 85], [90, 95]])\n",
    "# x_input = x_input.reshape((1, n_input))\n",
    "# yhat = model.predict(x_input, verbose=0)\n",
    "# print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "551185c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1711.7104 , 1696.6497 , 1699.6993 ],\n",
       "       [1712.1466 , 1698.3279 , 1702.0631 ],\n",
       "       [1723.6337 , 1707.6174 , 1709.5948 ],\n",
       "       ...,\n",
       "       [ 383.98666,  368.53622,  380.3894 ],\n",
       "       [ 344.2996 ,  352.89944,  391.5462 ],\n",
       "       [ 316.23843,  347.56784,  408.97418]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(X_test, verbose=0)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4c252c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1697., 1698., 1706.],\n",
       "       [1698., 1706., 1719.],\n",
       "       [1706., 1719., 1728.],\n",
       "       ...,\n",
       "       [ 384.,  341.,  310.],\n",
       "       [ 341.,  310.,  274.],\n",
       "       [ 310.,  274.,  241.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfdb3a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = pd.DataFrame(y_test)\n",
    "y_p = pd.DataFrame(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb754f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true,y_pred):\n",
    "    SSE = sum((y_true-y_pred)**2)\n",
    "    MSE = SSE/len(y_true)\n",
    "    RMSE = MSE**(1/2)\n",
    "    MAE = sum(abs(y_true-y_pred))/len(y_true)\n",
    "    MAPE = sum(abs(y_true-y_pred)/y_true)/len(y_true)*100\n",
    "    SD = (sum((abs(y_true-y_pred)-sum(abs(y_true-y_pred))/len(y_true))**2)/len(y_true))**(1/2)\n",
    "    r2s = r2_score(y_true, y_pred)\n",
    "    print('MSE: ', MSE, '\\n', 'RMSE: ', RMSE, '\\n','MAE: ', MAE, '\\n','MAPE: ', MAPE, '\\n','SD: ', SD, '\\n', 'R square: ', r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b2b3f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  14713.700159245122 \n",
      " RMSE:  121.30004187651842 \n",
      " MAE:  57.01136620693519 \n",
      " MAPE:  7.077160998262558 \n",
      " SD:  107.06728857341949 \n",
      " R square:  0.9316551356474456\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_t[2],y_p[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19245aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308533cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a97813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f487476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
